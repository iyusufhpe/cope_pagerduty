{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data files.\n",
    "\n",
    "import pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame saved to C:\\Users\\yusufi\\OneDrive - Hewlett Packard Enterprise\\SHARED_ONEDRIVE_HPEIY\\data\\combined_df.pkl\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Specify the directory containing JSON files\n",
    "json_folder = r'C:\\Users\\yusufi\\OneDrive - Hewlett Packard Enterprise\\SHARED_ONEDRIVE_HPEIY\\data\\json-files'\n",
    "\n",
    "# List all JSON files in the directory\n",
    "json_files = [f for f in os.listdir(json_folder) if f.endswith('.json')]\n",
    "\n",
    "# Initialize an empty list to hold DataFrames\n",
    "data_frames = []\n",
    "\n",
    "# Read each JSON file into a DataFrame and append to the list\n",
    "for json_file in json_files:\n",
    "    json_path = os.path.join(json_folder, json_file)\n",
    "    df = pd.read_json(json_path)\n",
    "    data_frames.append(df)\n",
    "\n",
    "# Combine all DataFrames into a single DataFrame\n",
    "combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "# Save the combined DataFrame to a binary file\n",
    "output_file = r'C:\\Users\\yusufi\\OneDrive - Hewlett Packard Enterprise\\SHARED_ONEDRIVE_HPEIY\\data\\combined_df.pkl'\n",
    "combined_df.to_pickle(output_file)\n",
    "\n",
    "# Display a message indicating the file has been saved\n",
    "print(f\"Combined DataFrame saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Read the combined panda dataframe\n",
    "- How many columns do I have.\n",
    "- select a subset of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df.columns = Index(['id', 'resolved_at', 'acknowledged_user_names', 'assigned_user_ids',\n",
      "       'service_id', 'urgency', 'created_at', 'acknowledgement_count',\n",
      "       'priority_order', 'escalation_count', 'user_defined_effort_seconds',\n",
      "       'manual_escalation_count', 'assignment_count', 'total_notifications',\n",
      "       'resolved_by_user_id', 'engaged_seconds', 'assigned_user_names',\n",
      "       'joined_user_ids', 'resolved_by_user_name', 'team_id',\n",
      "       'seconds_to_first_ack', 'team_name', 'total_interruptions',\n",
      "       'business_hour_interruptions', 'seconds_to_engage', 'priority_id',\n",
      "       'joined_user_names', 'off_hour_interruptions', 'snoozed_seconds',\n",
      "       'status', 'auto_resolved', 'updated_at', 'description',\n",
      "       'engaged_user_count', 'active_user_count', 'service_name',\n",
      "       'escalation_policy_name', 'sleep_hour_interruptions',\n",
      "       'escalation_policy_id', 'incident_number', 'major',\n",
      "       'seconds_to_mobilize', 'timeout_escalation_count', 'priority_name',\n",
      "       'reassignment_count', 'acknowledged_user_ids', 'seconds_to_resolve'],\n",
      "      dtype='object')\n",
      "Number of rows: 259639\n",
      "df.dtypesid                                     object\n",
      "resolved_at                    datetime64[ns]\n",
      "acknowledged_user_names                object\n",
      "assigned_user_ids                      object\n",
      "service_id                             object\n",
      "urgency                                object\n",
      "created_at                     datetime64[ns]\n",
      "acknowledgement_count                   int64\n",
      "priority_order                        float64\n",
      "escalation_count                        int64\n",
      "user_defined_effort_seconds           float64\n",
      "manual_escalation_count                 int64\n",
      "assignment_count                        int64\n",
      "total_notifications                     int64\n",
      "resolved_by_user_id                    object\n",
      "engaged_seconds                         int64\n",
      "assigned_user_names                    object\n",
      "joined_user_ids                        object\n",
      "resolved_by_user_name                  object\n",
      "team_id                                object\n",
      "seconds_to_first_ack                  float64\n",
      "team_name                              object\n",
      "total_interruptions                     int64\n",
      "business_hour_interruptions             int64\n",
      "seconds_to_engage                     float64\n",
      "priority_id                            object\n",
      "joined_user_names                      object\n",
      "off_hour_interruptions                  int64\n",
      "snoozed_seconds                         int64\n",
      "status                                 object\n",
      "auto_resolved                            bool\n",
      "updated_at                     datetime64[ns]\n",
      "description                            object\n",
      "engaged_user_count                      int64\n",
      "active_user_count                       int64\n",
      "service_name                           object\n",
      "escalation_policy_name                 object\n",
      "sleep_hour_interruptions                int64\n",
      "escalation_policy_id                   object\n",
      "incident_number                         int64\n",
      "major                                    bool\n",
      "seconds_to_mobilize                   float64\n",
      "timeout_escalation_count                int64\n",
      "priority_name                          object\n",
      "reassignment_count                      int64\n",
      "acknowledged_user_ids                  object\n",
      "seconds_to_resolve                    float64\n",
      "dtype: object\n",
      "df['incident_number'].dtypeint64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pickle_file = r'C:\\Users\\yusufi\\OneDrive - Hewlett Packard Enterprise\\SHARED_ONEDRIVE_HPEIY\\data\\combined_df.pkl'\n",
    "\n",
    "df = pd.read_pickle(pickle_file)\n",
    "\n",
    "print(f\"df.columns = {df.columns}\")\n",
    "print(f\"Number of rows: {len(df)}\")\n",
    "# Print the data types of all columns\n",
    "print(f\"df.dtypes{df.dtypes}\")\n",
    "# Print the data type of a specific column\n",
    "print(f\"df['incident_number'].dtype{df['incident_number'].dtype}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create a new dataframe with\n",
    "id, created_at, urgency, description, priority_name, auto_resolved,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id             resolved_at         acknowledged_user_names assigned_user_ids service_id urgency created_at           acknowledgement_count  priority_order  escalation_count  user_defined_effort_seconds  manual_escalation_count  assignment_count  total_notifications resolved_by_user_id  engaged_seconds assigned_user_names joined_user_ids resolved_by_user_name team_id  seconds_to_first_ack team_name          total_interruptions  business_hour_interruptions  seconds_to_engage priority_id joined_user_names  off_hour_interruptions  snoozed_seconds status    auto_resolved updated_at          description                                                                                       engaged_user_count  active_user_count service_name                       escalation_policy_name              sleep_hour_interruptions escalation_policy_id  incident_number  major  seconds_to_mobilize  timeout_escalation_count priority_name  reassignment_count acknowledged_user_ids  seconds_to_resolve\n",
      "Q3UDBNKUYA06UF 2024-09-22 11:04:56 [Ethan Williams]        [P0HRZWE]         PYWUGEI    high    2024-09-22 10:15:29 4                      2097152.0       0                 NaN                          0                        1                 8                    P0HRZWE             2822             [Ethan Williams]    [P0HRZWE]       Ethan Williams        PT5QHAT 39.0                  Nebula Operations 4                    0                            NaN                PAUKEFI     [Ethan Williams]  0                       0                resolved False          2024-09-22 16:13:46 [PROD-WEST] Chef client has not run successfully for over 60 minutes on microservice instance(s) 1                   1                  Nebula Infrastructure (Production) Nebula Infrastructure (Production) 4                         PU9VW8E              622139           True   NaN                  0                         P2            0                   [P0HRZWE]             2967.0             \n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "selected_fields = ['description','id','incident_number']\n",
    "dfselected = df[selected_fields]\n",
    "\n",
    "# Filter rows where the description contains \"domain name\" (case insensitive)\n",
    "# filtered_df = dfselected[~dfselected['description'].str.contains('Domain Name', case=False, na=False)]\n",
    "\n",
    "\n",
    "\n",
    "# Ensure the 'incident_number' column is of type int64\n",
    "df['incident_number'] = df['incident_number'].astype('int64')\n",
    "\n",
    "# Define the integer value to search for in the 'incident_number' field\n",
    "incident_number_to_search = 622139\n",
    "\n",
    "# Filter rows where the 'incident_number' field matches the specified integer value\n",
    "filtered_df = df[df['incident_number'] == incident_number_to_search]\n",
    "\n",
    "# Print the filtered DataFrame\n",
    "print(filtered_df.to_string(index=False, justify='left'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This incident has runbook. I have found it out using PagerDuty web. [Here is the link to the incident](https://hpe-hcss.pagerduty.com/incidents/Q3UDBNKUYA06UF)\n",
    "- Incident ID is = Q3UDBNKUYA06UF for Incident number 622139\n",
    "- Use this id to find Alert details???\n",
    "\n",
    "- Found a way to query alerts endpoint using CURL\n",
    "\n",
    "```curl\n",
    "    curl --request GET -k \\\n",
    "    --url https://api.pagerduty.com/incidents/Q3UDBNKUYA06UF/alerts \\\n",
    "    --header 'Accept: application/json' \\\n",
    "    --header 'Authorization: Token token=u+8Az15bpgqsshiJ2_Ng' \\\n",
    "    --header 'Content-Type: application/json' | pq\n",
    "```\n",
    "\n",
    "- Output\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"alerts\": [\n",
    "    {\n",
    "      \"id\": \"Q37X1X8YWMIQ2W\",\n",
    "      \"type\": \"alert\",\n",
    "      \"summary\": \"[PROD-WEST] Chef client has not run successfully for over 60 minutes on microservice instance(s)\",\n",
    "      \"self\": \"https://api.pagerduty.com/alerts/Q37X1X8YWMIQ2W\",\n",
    "      \"html_url\": \"https://hpe-hcss.pagerduty.com/alerts/Q37X1X8YWMIQ2W\",\n",
    "      \"created_at\": \"2024-09-22T04:15:29-06:00\",\n",
    "      \"status\": \"resolved\",\n",
    "      \"resolved_at\": \"2024-09-22T05:04:56-06:00\",\n",
    "      \"alert_key\": \"e5f252346bec0c06cd06511a599ec686c4858983a080f83a88ccb299bb3b3d7b\",\n",
    "      \"suppressed\": false,\n",
    "      \"service\": {\n",
    "        \"id\": \"PYWUGEI\",\n",
    "        \"type\": \"service_reference\",\n",
    "        \"summary\": \"Nebula Infrastructure (Production)\",\n",
    "        \"self\": \"https://api.pagerduty.com/services/PYWUGEI\",\n",
    "        \"html_url\": \"https://hpe-hcss.pagerduty.com/service-directory/PYWUGEI\"\n",
    "      },\n",
    "      \"severity\": \"error\",\n",
    "      \"incident\": {\n",
    "        \"id\": \"Q3UDBNKUYA06UF\",\n",
    "        \"type\": \"incident_reference\",\n",
    "        \"summary\": \"[#622139] [PROD-WEST] Chef client has not run successfully for over 60 minutes on microservice instance(s)\",\n",
    "        \"self\": \"https://api.pagerduty.com/incidents/Q3UDBNKUYA06UF\",\n",
    "        \"html_url\": \"https://hpe-hcss.pagerduty.com/incidents/Q3UDBNKUYA06UF\"\n",
    "      },\n",
    "      \"first_trigger_log_entry\": {\n",
    "        \"id\": \"RQHIXS2XWR1AS51YZJA9YUAW1U\",\n",
    "        \"type\": \"trigger_log_entry_reference\",\n",
    "        \"summary\": \"Triggered through the API.\",\n",
    "        \"self\": \"https://api.pagerduty.com/log_entries/RQHIXS2XWR1AS51YZJA9YUAW1U\",\n",
    "        \"html_url\": \"https://hpe-hcss.pagerduty.com/alerts/Q37X1X8YWMIQ2W/log_entries/RQHIXS2XWR1AS51YZJA9YUAW1U\"\n",
    "      },\n",
    "      \"body\": {\n",
    "        \"contexts\": [\n",
    "          {\n",
    "            \"type\": \"link\",\n",
    "            \"href\": \"https://hcss.atlassian.net/l/cp/yij1jp52\",\n",
    "            \"text\": \"Runbook\"\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"link\",\n",
    "            \"href\": \"https://grafana.bravo.cloudcruiser.com/d/RoybdEAMk/chef-client?var-env=prod-west\",\n",
    "            \"text\": \"Grafana Dashboard\"\n",
    "          },\n",
    "          {\n",
    "            \"type\": \"link\",\n",
    "            \"href\": \"https://prometheus.prod-west.cloudcruiser.com/graph?g0.expr=%28time%28%29+-+chef_client_last_run_timestamp_seconds%7Brole%3D~%22%28application%7Cplatform%7Ccc_generic%7Ccc_auth%29.%2A%22%7D%29+%3E+3600&g0.tab=1\",\n",
    "            \"text\": \"Prometheus Query\"\n",
    "          }\n",
    "        ],\n",
    "        \"details\": {\n",
    "          \"description\": \"Autoscaling activity could cause an outage if chef-client failures continue!\",\n",
    "          \"environment\": \"prod-west\",\n",
    "          \"firing\": \"Labels:\\n - alertname = ChefClientLastRunMicroservices\\n - ec2_instance_name = prod-west-platform-analytics-datamanagement-blue\\n - env = prod-west\\n - instance = 172.16.140.158\\n - job = node\\n - monitor = prometheus-prod-west-1\\n - role = platform_analytics_datamanagement\\n - severity = error\\n - team = devops\\nAnnotations:\\n - dashboard = https://grafana.bravo.cloudcruiser.com/d/RoybdEAMk/chef-client?var-env=prod-west\\n - description = Autoscaling activity could cause an outage if chef-client failures continue!\\n - runbook = https://hcss.atlassian.net/l/cp/yij1jp52\\n - summary = Chef client has not run successfully for over 60 minutes on microservice instance(s)\\nSource: https://prometheus.prod-west.cloudcruiser.com/graph?g0.expr=%28time%28%29+-+chef_client_last_run_timestamp_seconds%7Brole%3D~%22%28application%7Cplatform%7Ccc_generic%7Ccc_auth%29.%2A%22%7D%29+%3E+3600&g0.tab=1\\n\",\n",
    "          \"instance\": \"172.16.140.158\\n            \",\n",
    "          \"num_firing\": \"1\",\n",
    "          \"num_resolved\": \"0\",\n",
    "          \"resolved\": \"\",\n",
    "          \"service_name\": \"\",\n",
    "          \"summary\": \"[PROD-WEST] Chef client has not run successfully for over 60 minutes on microservice instance(s)\",\n",
    "          \"team\": \"devops\"\n",
    "        },\n",
    "        \"cef_details\": {\n",
    "          \"client\": \"Alertmanager\",\n",
    "          \"client_url\": \"https://alertmanager.prod-west.cloudcruiser.com/#/alerts?receiver=pagerduty\",\n",
    "          \"contexts\": [\n",
    "            {\n",
    "              \"href\": \"https://hcss.atlassian.net/l/cp/yij1jp52\",\n",
    "              \"text\": \"Runbook\",\n",
    "              \"type\": \"link\"\n",
    "            },\n",
    "            {\n",
    "              \"href\": \"https://grafana.bravo.cloudcruiser.com/d/RoybdEAMk/chef-client?var-env=prod-west\",\n",
    "              \"text\": \"Grafana Dashboard\",\n",
    "              \"type\": \"link\"\n",
    "            },\n",
    "            {\n",
    "              \"href\": \"https://prometheus.prod-west.cloudcruiser.com/graph?g0.expr=%28time%28%29+-+chef_client_last_run_timestamp_seconds%7Brole%3D~%22%28application%7Cplatform%7Ccc_generic%7Ccc_auth%29.%2A%22%7D%29+%3E+3600&g0.tab=1\",\n",
    "              \"text\": \"Prometheus Query\",\n",
    "              \"type\": \"link\"\n",
    "            }\n",
    "          ],\n",
    "          \"dedup_key\": \"e5f252346bec0c06cd06511a599ec686c4858983a080f83a88ccb299bb3b3d7b\",\n",
    "          \"description\": \"[PROD-WEST] Chef client has not run successfully for over 60 minutes on microservice instance(s)\",\n",
    "          \"details\": {\n",
    "            \"description\": \"Autoscaling activity could cause an outage if chef-client failures continue!\",\n",
    "            \"environment\": \"prod-west\",\n",
    "            \"firing\": \"Labels:\\n - alertname = ChefClientLastRunMicroservices\\n - ec2_instance_name = prod-west-platform-analytics-datamanagement-blue\\n - env = prod-west\\n - instance = 172.16.140.158\\n - job = node\\n - monitor = prometheus-prod-west-1\\n - role = platform_analytics_datamanagement\\n - severity = error\\n - team = devops\\nAnnotations:\\n - dashboard = https://grafana.bravo.cloudcruiser.com/d/RoybdEAMk/chef-client?var-env=prod-west\\n - description = Autoscaling activity could cause an outage if chef-client failures continue!\\n - runbook = https://hcss.atlassian.net/l/cp/yij1jp52\\n - summary = Chef client has not run successfully for over 60 minutes on microservice instance(s)\\nSource: https://prometheus.prod-west.cloudcruiser.com/graph?g0.expr=%28time%28%29+-+chef_client_last_run_timestamp_seconds%7Brole%3D~%22%28application%7Cplatform%7Ccc_generic%7Ccc_auth%29.%2A%22%7D%29+%3E+3600&g0.tab=1\\n\",\n",
    "            \"instance\": \"172.16.140.158\\n            \",\n",
    "            \"num_firing\": \"1\",\n",
    "            \"num_resolved\": \"0\",\n",
    "            \"resolved\": \"\",\n",
    "            \"service_name\": \"\",\n",
    "            \"summary\": \"[PROD-WEST] Chef client has not run successfully for over 60 minutes on microservice instance(s)\",\n",
    "            \"team\": \"devops\"\n",
    "          },\n",
    "          \"severity\": \"error\",\n",
    "          \"source_origin\": \"Alertmanager\"\n",
    "        },\n",
    "        \"type\": \"alert_body\"\n",
    "      },\n",
    "      \"integration\": null,\n",
    "      \"privilege\": null\n",
    "    }\n",
    "  ],\n",
    "  \"limit\": 25,\n",
    "  \"offset\": 0,\n",
    "  \"more\": false,\n",
    "  \"total\": null\n",
    "}\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".virtualenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
